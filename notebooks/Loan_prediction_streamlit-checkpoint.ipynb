{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Déploiement de modèles d'apprentissage automatique à l'aide de Streamlit - Guide d'introduction au déploiement de modèles\n",
    "\n",
    "### Aperçu\n",
    "   - Comprendre le concept de déploiement de modèle\n",
    "   - Effectuer le déploiement du modèle à l'aide de Streamlit pour les données de prévision de prêt\n",
    " \n",
    "\n",
    "### introduction\n",
    "Je pense que la plupart d'entre vous doivent avoir réalisé une forme de projet de science des données à un moment donné de leur vie, qu'il s'agisse d'un projet d'apprentissage automatique, d'un projet d'apprentissage en profondeur ou même de visualisations de vos données. Et la meilleure partie de ces projets est de les présenter aux autres. Cela vous motivera et vous encouragera non seulement dans votre travail acharné, mais vous aidera également à améliorer votre projet.\n",
    "\n",
    "Mais la question est de savoir comment allez-vous présenter votre travail aux autres ? Eh bien, c'est là que Model Deployment vous aidera.\n",
    "\n",
    "J'explore le domaine du déploiement de modèles depuis quelques mois maintenant. Le déploiement de modèles vous aide à présenter votre travail au monde et à prendre de meilleures décisions avec. Mais le déploiement d'un modèle peut parfois devenir un peu délicat. Avant de déployer le modèle, de nombreux éléments doivent être examinés, tels que le stockage des données, le prétraitement, la création de modèles et la surveillance. Cela peut être un peu déroutant car le nombre d'outils qui effectuent efficacement ces tâches de déploiement de modèle est peu nombreux. Entrez, Streamlit!\n",
    "\n",
    "Streamlit est un framework open source populaire utilisé pour le déploiement de modèles par les équipes d'apprentissage automatique et de science des données. Et la meilleure partie est que c'est gratuit et purement en python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dans cet article, nous allons approfondir le déploiement de modèles. Nous allons d'abord construire un modèle de prédiction de prêt, puis le déployer à l'aide de Streamlit.**\n",
    "\n",
    " \n",
    "\n",
    "## Table des matières\n",
    "1. Présentation du cycle de vie de l'apprentissage automatique\n",
    "2. Comprendre l'énoncé du problème : automatisation de la prévision des prêts\n",
    "3. Modèle d'apprentissage automatique pour l'automatisation de la prévision des prêts\n",
    "4. Introduction à Streamlit\n",
    "6. Déploiement du modèle du modèle de prévision de prêt à l'aide de Streamlit\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Présentation du cycle de vie de l'apprentissage automatique\n",
    "Commençons par comprendre le cycle de vie global de l'apprentissage automatique et les différentes étapes impliquées dans la création d'un projet d'apprentissage automatique. Globalement, l'ensemble du cycle de vie de l'apprentissage automatique peut être décrit comme une combinaison de 6 étapes. Permettez-moi de briser ces étapes pour vous :**\n",
    "\n",
    "#### Étape 1 : Définition du problème\n",
    "La première et la plus importante partie de tout projet est de définir l'énoncé du problème. Ici, nous voulons décrire le but ou le but de notre projet et ce que nous voulons atteindre à la fin.\n",
    "\n",
    "#### Étape 2 : Génération d'hypothèses\n",
    "Une fois l'énoncé du problème finalisé, nous passons à la partie génération d'hypothèses. Ici, nous essayons de souligner les facteurs/caractéristiques qui peuvent nous aider à résoudre le problème en question.\n",
    "\n",
    "#### Étape 3 : Collecte de données\n",
    "Après avoir généré des hypothèses, nous obtenons la liste des fonctionnalités utiles pour un problème. Ensuite, nous collectons les données en conséquence. Ces données peuvent être collectées à partir de différentes sources.\n",
    "\n",
    "#### Étape 4 : Exploration et pré-traitement des données\n",
    "Après avoir collecté les données, nous passons à l'exploration et au pré-traitement. Ces étapes nous aident à générer des informations significatives à partir des données. Nous nettoyons également l'ensemble de données dans cette étape, avant de construire le modèle\n",
    "\n",
    "#### Étape 5 : Construction de modèles\n",
    "Une fois que nous avons exploré et prétraité l'ensemble de données, l'étape suivante consiste à construire le modèle. Ici, nous créons des modèles prédictifs afin de construire une solution pour le projet.\n",
    "\n",
    "#### Étape 6 : Déploiement du modèle\n",
    "Une fois que vous avez la solution, vous voulez la présenter et la rendre accessible aux autres. Et par conséquent, la dernière étape du cycle de vie de l'apprentissage automatique consiste à déployer ce modèle.\n",
    "\n",
    "Ce sont les 6 étapes d'un cycle de vie d'apprentissage automatique. Le but de cet article est de comprendre en détail la dernière étape, c'est-à-dire le déploiement du modèle, à l'aide de streamlit. Cependant, j'expliquerai brièvement les étapes restantes et le cycle de vie complet de l'apprentissage automatique ainsi que leur implémentation en Python, avant de plonger profondément dans la partie déploiement du modèle à l'aide de streamlit.\n",
    "\n",
    "Donc, dans la section suivante, commençons par comprendre l'énoncé du problème.\n",
    "\n",
    "\n",
    "# Comprendre l'énoncé du problème : automatisation de la prévision des prêts\n",
    "Le projet que j'ai choisi pour ce blog particulier automatise le processus d'éligibilité au prêt. La tâche consiste à prédire si le prêt sera approuvé ou non en fonction des détails fournis par les clients. Voici l' énoncé du problème pour ce projet :\n",
    "\n",
    "Automatisez le processus d'éligibilité au prêt en fonction des détails du client fournis lors du remplissage du formulaire de demande en ligne\n",
    "\n",
    "Sur la base des détails fournis par les clients, nous devons créer un modèle qui peut décider où leur prêt doit être approuvé ou non. Ceci termine la partie définition du problème de la première étape du cycle de vie de l'apprentissage automatique. L'étape suivante consiste à générer des hypothèses et à indiquer les facteurs qui nous aideront à prédire si le prêt d'un client doit être approuvé ou non.\n",
    "\n",
    "#### Pour commencer, voici quelques facteurs qui, à mon avis, nous seront utiles dans le cadre de ce projet :\n",
    "\n",
    "   - **Montant du prêt :** Le montant total du prêt appliqué par le client. Mon hypothèse ici est que plus le montant du prêt est élevé, plus les chances d'approbation du prêt seront faibles et vice versa.\n",
    "   - **Revenu du demandeur :** Le revenu du demandeur (client) peut également être un facteur déterminant. Un revenu plus élevé entraînera une probabilité plus élevée d'approbation de prêt.\n",
    "   - **Éducation du demandeur :** Le niveau d'études du demandeur peut également être un facteur essentiel pour prédire le statut de prêt d'un client. Mon hypothèse est que si le niveau d'études du demandeur est plus élevé, les chances d'approbation de son prêt seront plus élevées.\n",
    "  \n",
    "Ce sont là quelques facteurs qui peuvent être utiles pour prédire l'état du prêt d'un client. Évidemment, c'est une très petite liste, et vous pouvez proposer beaucoup plus d'hypothèses. Mais, étant donné que cet article se concentre sur le déploiement de modèles, je vous laisserai explorer plus avant cette partie de génération d'hypothèses.\n",
    "\n",
    "\n",
    "Nous avons quelques variables liées au prêt, comme l'identifiant du prêt, qui est l'identifiant unique de chaque client, le montant du prêt et la durée du prêt, qui nous indiquent respectivement le montant du prêt en milliers et la durée du prêt en mois. L'historique de crédit indique si un client a des dettes antérieures non claires ou non. En dehors de cela, nous avons également des détails sur les clients, comme leur sexe, leur état civil, leur diplôme, leurs revenus, etc. En utilisant ces fonctionnalités, nous allons créer un modèle prédictif qui prédit la variable cible qui est le statut du prêt représentant si le prêt sera approuvé ou non.\n",
    "\n",
    "Nous avons maintenant finalisé l'énoncé du problème, généré les hypothèses et collecté les données. Viennent ensuite la phase d' exploration et de pré-traitement des données . Ici, nous allons explorer l'ensemble de données et le pré-traiter. Les étapes courantes de cette étape sont les suivantes :\n",
    "\n",
    "- Analyse univariée\n",
    "- Analyse bivariée\n",
    "- Traitement de la valeur manquante\n",
    "- Traitement des valeurs aberrantes\n",
    "- Ingénierie des fonctionnalités\n",
    "Nous explorons les variables individuellement, ce qu'on appelle l'analyse univariée. L'analyse bivariée consiste à explorer l'effet d'une variable sur l'autre ou à explorer deux variables à la fois. Nous recherchons également les valeurs manquantes ou les valeurs aberrantes qui pourraient être présentes dans l'ensemble de données et les traitons. Et nous pourrions également créer de nouvelles fonctionnalités en utilisant les fonctionnalités existantes appelées ingénierie des fonctionnalités. Encore une fois, je ne me concentrerai pas beaucoup sur ces parties d'exploration de données et ne ferai que le pré-traitement nécessaire.\n",
    "\n",
    "Après avoir exploré et prétraité les données, vient ensuite la phase de construction du modèle. Puisqu'il s'agit d'un problème de classification, nous pouvons utiliser n'importe quel modèle de classification comme la régression logistique, l'arbre de décision, la forêt aléatoire, etc. J'ai essayé tous ces 3 modèles pour ce problème et la forêt aléatoire a produit les meilleurs résultats. Je vais donc utiliser une forêt aléatoire comme modèle prédictif pour ce projet.\n",
    "\n",
    "Jusqu'à présent, j'ai brièvement expliqué les cinq premières étapes du cycle de vie de l'apprentissage automatique en ce qui concerne le projet d'automatisation de la prévision des prêts. Ensuite, je vais démontrer ces étapes en Python.\n",
    "\n",
    "\n",
    "## Modèle d'apprentissage automatique pour l'automatisation de la prévision des prêts\n",
    "Dans cette section, je vais démontrer les cinq premières étapes du cycle de vie de l'apprentissage automatique pour le projet en cours. Les deux premières étapes, c'est-à-dire la définition du problème et la génération d'hypothèses sont déjà couvertes dans la section précédente et donc commençons par la troisième étape et chargeons l'ensemble de données. Pour cela, nous allons d'abord importer les bibliothèques requises puis lire le fichier CSV :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\BARRY MOHAMED\\\\Desktop\\\\Test\\\\Test'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/BARRY MOHAMED/Documents/Udemy/streamlit/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"C:/Users/BARRY MOHAMED/Documents/Udemy/streamlit/\"\n",
    "os.chdir(path)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "train = pd.read_csv('train_loan.csv') \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les cinq premières lignes de l'ensemble de données. Nous savons que les modèles d'apprentissage automatique ne prennent que des nombres en entrée et ne peuvent pas traiter des chaînes. Nous devons donc traiter les catégories présentes dans l'ensemble de données et les convertir en nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID  Gender  Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002     0.0      0.0          0      Graduate            No   \n",
       "1  LP001003     0.0      1.0          1      Graduate            No   \n",
       "2  LP001005     0.0      1.0          0      Graduate           Yes   \n",
       "3  LP001006     0.0      1.0          0  Not Graduate            No   \n",
       "4  LP001008     0.0      0.0          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area  Loan_Status  \n",
       "0             1.0         Urban            1  \n",
       "1             1.0         Rural            0  \n",
       "2             1.0         Urban            1  \n",
       "3             1.0         Urban            1  \n",
       "4             1.0         Urban            1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Gender']= train['Gender'].map({'Male':0, 'Female':1})\n",
    "train['Married']= train['Married'].map({'No':0, 'Yes':1})\n",
    "train['Loan_Status']= train['Loan_Status'].map({'N':0, 'Y':1})\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous avons converti les catégories présentes dans la variable Sexe, Marié et Statut du prêt en nombres, en utilisant simplement la fonction map de python. Ensuite, vérifions s'il y a des valeurs manquantes dans l'ensemble de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, il y a des valeurs manquantes sur de nombreuses variables, y compris la variable Sexe, Marié, Montant du prêt. Ensuite, nous supprimerons toutes les lignes qui contiennent des valeurs manquantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.dropna()\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, il n'y a plus de valeurs manquantes dans l'ensemble de données. Ensuite, nous séparerons les variables dépendantes (Loan_Status) et indépendantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((480, 5), (480,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train[['Gender', 'Married', 'ApplicantIncome', 'LoanAmount', 'Credit_History']]\n",
    "y = train.Loan_Status\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce projet particulier, je n'ai choisi que 5 variables qui me semblent les plus pertinentes. Il s'agit du sexe, de l'état matrimonial, du revenu du demandeur, du montant du prêt et de l'historique de crédit et les a stockés dans la variable X. La variable cible est stockée dans une autre variable y. Et il y a 480 observations disponibles. Passons ensuite à l'étape de construction du modèle.\n",
    "\n",
    "Ici, nous allons d'abord diviser notre ensemble de données en un ensemble d'apprentissage et de validation, afin que nous puissions entraîner le modèle sur l'ensemble d'apprentissage et évaluer ses performances sur l'ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X,y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons divisé les données à l'aide de la fonction train_test_split de la bibliothèque sklearn en conservant la valeur test_size à 0,2, ce qui signifie que 20 % de l'ensemble de données total seront conservés pour l'ensemble de validation. Ensuite, nous allons entraîner le modèle de forêt aléatoire à l'aide de l'ensemble d'apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, random_state=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "model = RandomForestClassifier(max_depth=4, random_state = 10) \n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, j'ai gardé le max_depth à 4 pour chacun des arbres de notre forêt aléatoire et j'ai stocké le modèle formé dans une variable nommée model. Maintenant que notre modèle est entraîné, vérifions ses performances à la fois sur l'ensemble d'entraînement et de validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8020833333333334"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred_cv = model.predict(x_cv)\n",
    "accuracy_score(y_cv,pred_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle est précis à 80 % sur l'ensemble de validation. Vérifions également les performances sur l'ensemble d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8203125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train = model.predict(x_train)\n",
    "accuracy_score(y_train,pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les performances sur l'ensemble d'apprentissage sont presque similaires à celles sur l'ensemble de validation. Le modèle s'est donc bien généralisé. Enfin, nous enregistrerons ce modèle entraîné afin qu'il puisse être utilisé à l'avenir pour faire des prédictions sur de nouvelles observations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model \n",
    "import pickle \n",
    "pickle_out = open(\"classifier.pkl\", mode = \"wb\") \n",
    "pickle.dump(model, pickle_out) \n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous enregistrons le modèle au format pickle et le stockons sous classifier.pkl. Cela stockera le modèle formé et nous l'utiliserons lors du déploiement du modèle.\n",
    "\n",
    "Ceci termine les cinq premières étapes du cycle de vie de l'apprentissage automatique. Ensuite, nous explorerons la dernière étape qui est le déploiement du modèle. Nous allons déployer ce modèle de prédiction de prêt afin qu'il soit accessible à d'autres. Et pour ce faire, nous utiliserons Streamlit qui est un moyen récent et le plus simple de créer des applications Web et de déployer des modèles de machine learning et de deep learning.\n",
    "\n",
    "Commençons donc par discuter de cet outil, puis je vous montrerai comment déployer votre modèle d'apprentissage automatique en l'utilisant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selon les fondateurs de Streamlit, c'est le moyen le plus rapide de créer des applications de données et de les partager. Il s'agit d'un outil de déploiement de modèle récent qui simplifie l'ensemble du cycle de déploiement de modèle et vous permet de déployer vos modèles rapidement. J'explore cet outil depuis quelques semaines et selon mon expérience, c'est un outil de déploiement de modèle simple, rapide et interprétable.\n",
    "\n",
    "Voici quelques-unes des fonctionnalités clés de Streamlit que j'ai trouvées vraiment intéressantes et utiles :\n",
    "\n",
    "1. Il transforme rapidement les scripts de données en applications Web partageables . Il vous suffit de transmettre un script en cours d'exécution à l'outil et il peut le convertir en une application Web.\n",
    "2. Tout en Python . La meilleure chose à propos de Streamlit est que tout ce que nous faisons est en Python. Du chargement du modèle à la création du frontend, tout peut être fait en utilisant Python.\n",
    "3. Le tout gratuitement . C'est open source et donc aucun coût n'est impliqué. Vous pouvez déployer vos applications sans les payer.\n",
    "4. Aucune expérience en front-end requise . Le déploiement du modèle contient généralement deux parties, le frontend et le backend. Le backend est généralement un modèle de travail, un modèle d'apprentissage automatique dans notre cas, qui est un python intégré. Et la partie frontale, qui nécessite généralement une certaine connaissance d'autres langages comme les scripts java, etc. En utilisant Streamlit, nous pouvons créer ce frontal en Python lui-même. Nous n'avons donc pas besoin d'apprendre d'autres langages de programmation ou techniques de développement Web. Comprendre Python est suffisant.\n",
    "\n",
    "Disons que nous déployons le modèle sans utiliser Streamlit. Dans ce cas, l'ensemble du pipeline ressemblera à ceci :\n",
    "\n",
    "- Construction de modèles\n",
    "- Création d'un script python\n",
    "- Écrire l'application Flask\n",
    "- Créer un front-end : JavaScript\n",
    "- Déployer\n",
    "Nous allons d'abord construire notre modèle et le convertir en un script python. Ensuite, nous devrons créer l'application Web en utilisant disons flask. Nous devrons également créer le front end pour l'application Web et ici, nous devrons utiliser JavaScript. Et puis enfin, nous allons déployer le modèle. Donc, si vous le remarquez, nous aurons besoin des connaissances de Python pour construire le modèle, puis d'une compréhension approfondie de JavaScript et de Flask pour construire le front-end et déployer le modèle. Examinons maintenant le pipeline de déploiement si nous utilisons Streamlit :\n",
    "\n",
    "Construction de modèles\n",
    "Création d'un script python\n",
    "Créer un front-end : Python\n",
    "Déployer\n",
    "Ici, nous allons construire le modèle et créer un script python pour celui-ci. Ensuite, nous allons construire le front-end de l'application qui sera en python et enfin, nous allons déployer le modèle. C'est ça. Notre modèle sera déployé. N'est-ce pas incroyable? Si vous connaissez python, le déploiement de modèles à l'aide de Streamlit sera un voyage facile. J'espère que vous êtes aussi enthousiasmé par Streamlit que je l'étais en l'explorant plus tôt. Alors, sans plus tarder, créons notre propre application Web à l'aide de Streamlit.\n",
    "\n",
    "### Déploiement du modèle du modèle de prévision de prêt à l'aide de Streamlit\n",
    "Nous allons commencer par les installations de base :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyngrok\n",
    "\n",
    "!pip install -q streamlit\n",
    "\n",
    "!pip install -q streamlit_ace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons installé 3 bibliothèques ici. pyngrok est un wrapper python pour ngrok qui permet d'ouvrir des tunnels sécurisés à partir d'URL publiques vers localhost. Cela nous aidera à héberger notre application Web. Streamlit sera utilisé pour créer notre application Web. \n",
    "\n",
    "Ensuite, nous devrons créer une session distincte dans Streamlit pour notre application. Vous pouvez télécharger le fichier sessionstate.py à partir d'ici (https://drive.google.com/file/d/1D1HLyHfCAY2Bt0aVMFHVlLsSg4mUkon-/view) et le stocker dans votre répertoire de travail actuel. Cela vous aidera à créer une session pour votre application. Enfin, nous devons créer le script python pour notre application. Laissez-moi d'abord montrer le code, puis je vous l'expliquerai en détail :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%writefile` not found.\n"
     ]
    }
   ],
   "source": [
    "#Dans cette partie, nous enregistrons le script sous le nom app.py, puis nous chargeons les bibliothèques requises qui sont \n",
    "#pickle pour charger le modèle entraîné et rationalisées pour créer l'application. Ensuite, nous chargeons le modèle entraîné et\n",
    "#l'enregistrons dans une variable nommée classifier.\n",
    "\n",
    "\n",
    "%%writefile app.py\n",
    " \n",
    "import pickle\n",
    "import streamlit as st\n",
    " \n",
    "# loading the trained model\n",
    "pickle_in = open('classifier.pkl', 'rb') \n",
    "classifier = pickle.load(pickle_in)\n",
    " \n",
    "@st.cache()\n",
    "\n",
    "#Ensuite, nous avons défini la fonction de prédiction. Cette fonction prendra en entrée les données fournies par les utilisateurs\n",
    "#et effectuera la prédiction à l'aide du modèle que nous avons chargé précédemment. Il prendra les détails du client comme le \n",
    "#sexe, l'état matrimonial, le revenu, le montant du prêt et l'historique de crédit comme entrée, puis pré-traitera cette entrée \n",
    "#afin qu'elle puisse être alimentée dans le modèle et enfin, faire la prédiction à l'aide du modèle chargé en tant que \n",
    "#classificateur. En fin de compte, il indiquera si le prêt est approuvé ou non en fonction des résultats du modèle.\n",
    "\n",
    "# defining the function which will make the prediction using the data which the user inputs \n",
    "def prediction(Gender, Married, ApplicantIncome, LoanAmount, Credit_History):   \n",
    " \n",
    "    # Pre-processing user input    \n",
    "    if Gender == \"Male\":\n",
    "        Gender = 0\n",
    "    else:\n",
    "        Gender = 1\n",
    " \n",
    "    if Married == \"Unmarried\":\n",
    "        Married = 0\n",
    "    else:\n",
    "        Married = 1\n",
    " \n",
    "    if Credit_History == \"Unclear Debts\":\n",
    "        Credit_History = 0\n",
    "    else:\n",
    "        Credit_History = 1  \n",
    " \n",
    "    LoanAmount = LoanAmount / 1000\n",
    " \n",
    "    # Making predictions \n",
    "    prediction = classifier.predict( \n",
    "        [[Gender, Married, ApplicantIncome, LoanAmount, Credit_History]])\n",
    "     \n",
    "    if prediction == 0:\n",
    "        pred = 'Rejected'\n",
    "    else:\n",
    "        pred = 'Approved'\n",
    "    return pred\n",
    "      \n",
    "#Et voici l'application principale. Tout d'abord, nous définissons l'en-tête de l'application. Il affichera \"Streamlit Loan \n",
    "#Prediction ML App\". Pour ce faire, nous utilisons la fonction markdown de streamlit. Ensuite, nous créons cinq cases dans \n",
    "#l'application pour recueillir les commentaires des utilisateurs. Ces 5 cases représenteront les cinq caractéristiques sur \n",
    "#lesquelles notre modèle est formé. \n",
    "\n",
    "#La première case correspond au sexe de l'utilisateur. L'utilisateur aura deux options, Homme et Femme, et il devra en choisir \n",
    "#une. Nous créons une liste déroulante en utilisant la fonction selectbox de streamlit. De même, pour Marié, nous proposons deux\n",
    "#options, Marié et Célibataire et encore une fois, l'utilisateur en choisira une. Ensuite, nous définissons les cases pour le \n",
    "#revenu du demandeur et le montant du prêt.\n",
    "\n",
    "#Étant donné que ces deux variables seront de nature numérique, nous utilisons la fonction number_input de streamlit. Et enfin, \n",
    "#pour l'historique de crédit, nous créons une liste déroulante qui comportera deux catégories, Dettes non claires et Dettes non \n",
    "#claires. \n",
    "\n",
    "#À la fin de l'application, il y aura un bouton de prédiction et après avoir rempli les détails, les utilisateurs doivent cliquer sur ce bouton. Une fois ce bouton cliqué, la fonction de prédiction sera appelée et le résultat du statut du prêt sera affiché dans l'application. Ceci termine la partie de création de l'application Web. Et vous avez dû remarquer que tout ce que nous avons fait est en python. N'est-ce pas génial?\n",
    "\n",
    "\n",
    "# this is the main function in which we define our webpage  \n",
    "def main():       \n",
    "    # front end elements of the web page \n",
    "    html_temp = \"\"\" \n",
    "    <div style =\"background-color:yellow;padding:13px\"> \n",
    "    <h1 style =\"color:black;text-align:center;\">Streamlit Loan Prediction ML App</h1> \n",
    "    </div> \n",
    "    \"\"\"\n",
    "      \n",
    "    # display the front end aspect\n",
    "    st.markdown(html_temp, unsafe_allow_html = True) \n",
    "      \n",
    "    # following lines create boxes in which user can enter data required to make prediction \n",
    "    Gender = st.selectbox('Gender',(\"Male\",\"Female\"))\n",
    "    Married = st.selectbox('Marital Status',(\"Unmarried\",\"Married\")) \n",
    "    ApplicantIncome = st.number_input(\"Applicants monthly income\") \n",
    "    LoanAmount = st.number_input(\"Total loan amount\")\n",
    "    Credit_History = st.selectbox('Credit_History',(\"Unclear Debts\",\"No Unclear Debts\"))\n",
    "    result =\"\"\n",
    "      \n",
    "    # when 'Predict' is clicked, make the prediction and store it \n",
    "    if st.button(\"Predict\"): \n",
    "        result = prediction(Gender, Married, ApplicantIncome, LoanAmount, Credit_History) \n",
    "        st.success('Your loan is {}'.format(result))\n",
    "        print(LoanAmount)\n",
    "     \n",
    "if __name__=='__main__': \n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est l'intégralité du script python qui créera l'application pour nous. Permettez-moi de le décomposer et d'expliquer en détail:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'accord, hébergeons maintenant cette application sur une URL publique à l'aide de la bibliothèque pyngrok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Background processes not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-505e615d0295>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'streamlit run app.py &>/dev/null&'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda8\\lib\\site-packages\\ipykernel\\zmqshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[1;34m(self, cmd)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;31m# os.system() or use ip.system=ip.system_raw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m             \u001b[1;31m# if they really want a background process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Background processes not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;31m# we explicitly do NOT return the subprocess status code, because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Background processes not supported."
     ]
    }
   ],
   "source": [
    "!streamlit run app.py &>/dev/null&"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous exécutons d'abord le script python. Et puis nous le connecterons à une URL publique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-26 20:21:53.465 Opening tunnel named: http-8501-d551a993-206c-4ee0-b03c-9978c13063de\n",
      "2021-08-26 20:21:53.511 t=2021-08-26T20:21:53+0200 lvl=info msg=start pg=/api/tunnels id=0dc16609c2aadd0e\n",
      "2021-08-26 20:21:53.581 t=2021-08-26T20:21:53+0200 lvl=warn msg=\"failed to start tunnel\" pg=/api/tunnels id=0dc16609c2aadd0e err=\"Your account may not run more than 2 tunnels over a single ngrok client session.\\nThe tunnels already running on this session are:\\ntn_1xHB9oHVQnG6pZ2vfv8ERT2sySH, tn_1xHB9tGH59NxlOeuZeFGctsagGK\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"\n",
      "2021-08-26 20:21:53.585 t=2021-08-26T20:21:53+0200 lvl=info msg=end pg=/api/tunnels id=0dc16609c2aadd0e status=502 dur=109.647ms\n"
     ]
    },
    {
     "ename": "PyngrokNgrokHTTPError",
     "evalue": "ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"Your account may not run more than 2 tunnels over a single ngrok client session.\\nThe tunnels already running on this session are:\\ntn_1xHB9oHVQnG6pZ2vfv8ERT2sySH, tn_1xHB9tGH59NxlOeuZeFGctsagGK\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"}}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda8\\lib\\site-packages\\pyngrok\\ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[1;34m(url, method, data, params, timeout)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda8\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda8\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda8\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             response = self.parent.error(\n\u001b[0m\u001b[0;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
      "\u001b[1;32m~\\anaconda8\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda8\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda8\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 502: Bad Gateway",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPyngrokNgrokHTTPError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-835d45517961>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyngrok\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mngrok\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpublic_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'8501'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cela générera un lien comme celui-ci :'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda8\\lib\\site-packages\\pyngrok\\ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Creating tunnel with options: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m     tunnel = NgrokTunnel(api_request(\"{}/api/tunnels\".format(api_url), method=\"POST\", data=options,\n\u001b[0m\u001b[0;32m    256\u001b[0m                                      timeout=pyngrok_config.request_timeout),\n\u001b[0;32m    257\u001b[0m                          pyngrok_config, api_url)\n",
      "\u001b[1;32m~\\anaconda8\\lib\\site-packages\\pyngrok\\ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[1;34m(url, method, data, params, timeout)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Response {}: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         raise PyngrokNgrokHTTPError(\"ngrok client exception, API returned {}: {}\".format(status_code, response_data),\n\u001b[0m\u001b[0;32m    462\u001b[0m                                     \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m                                     status_code, e.msg, e.hdrs, response_data)\n",
      "\u001b[1;31mPyngrokNgrokHTTPError\u001b[0m: ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"Your account may not run more than 2 tunnels over a single ngrok client session.\\nThe tunnels already running on this session are:\\ntn_1xHB9oHVQnG6pZ2vfv8ERT2sySH, tn_1xHB9tGH59NxlOeuZeFGctsagGK\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"}}\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    " \n",
    "public_url = ngrok.connect('8501')\n",
    "\n",
    "print('Cela générera un lien comme celui-ci :')\n",
    "public_url\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que le lien variera de votre côté. Vous pouvez cliquer sur le lien qui vous mènera à l'application Web :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes de fin\n",
    "Toutes nos félicitations! Nous avons maintenant terminé avec succès le déploiement du modèle de prévision des prêts à l'aide de Streamlit. Je vous encourage à essayer d'abord ce projet particulier, à jouer avec les valeurs en entrée et à vérifier les résultats. Et puis, vous pouvez également essayer d'autres projets d'apprentissage automatique et effectuer le déploiement de modèles à l'aide de streamlit. \n",
    "\n",
    "Le déploiement est simple, rapide et surtout en Python. Cependant, il y a quelques défis avec cela. Nous avons utilisé Google Colab comme backend pour nous construire et comme vous le savez peut-être, la session Colab redémarre automatiquement après 12 heures. De plus, si votre connexion Internet est interrompue, la session Colab s'interrompt. Par conséquent, si nous utilisons Colab comme backend, nous devons réexécuter l'intégralité de l'application une fois la session expirée. \n",
    "\n",
    "Nous vous recommandons de parcourir les articles suivants sur le déploiement de modèles pour solidifier vos concepts-\n",
    "\n",
    "La puissance d'Azure ML et de Power BI : flux de données et déploiement de modèles\n",
    "Déploiement de modèles de ML dans le Cloud – AWS SageMaker (algorithmes intégrés)\n",
    "Déployer un modèle de classification d'images à l'aide de Flask\n",
    "Pour faire face à cela, nous pouvons changer le backend. AWS peut être la bonne option ici pour le backend et en utilisant cela, nous pouvons héberger notre application Web de manière permanente. Ainsi, dans mon prochain article, je montrerai comment intégrer AWS à Streamlit et rendre le processus de déploiement de modèle plus efficace.\n",
    "\n",
    "Enfin, j'aimerais entendre vos commentaires et suggestions pour cet article. Si vous avez des questions concernant l'article, postez-les dans la section commentaires ci-dessous. Je vais les regarder activement et y répondre.\n",
    "\n",
    "En rapport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
